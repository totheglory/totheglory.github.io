{"meta":{"title":"terrence mu's blog","subtitle":null,"description":"keep moving","author":"terrence mu","url":"http://yoursite.com"},"pages":[{"title":"about","date":"2017-07-21T05:09:54.000Z","updated":"2017-07-21T05:09:54.000Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"","raw":null,"content":null}],"posts":[{"title":"正则表达式Tips","slug":"regextips","date":"2017-08-23T01:09:07.000Z","updated":"2017-08-30T09:12:46.000Z","comments":true,"path":"2017/08/23/regextips/","link":"","permalink":"http://yoursite.com/2017/08/23/regextips/","excerpt":"","text":"正则表达式引擎正则表达式的正则引擎主要分为两大类：DFA和NFA，NFA又细分为传统型NFA，POSIX NFA。 DFA（确定型有穷机） 以文本主导的匹配。匹配规则是从匹配文本入手，从左至右，每个字符的匹配次数不会超过两次。 多条子表达式会在扫描文本时，同时进行匹配 不支持捕获组，各种引用，贪心修饰符等。 时间复杂度是多项式级别的。 可以确保匹配最长的可能的字符串。 使用DFA引擎 awk，MySQL，egrep等 NFA （非确定性有穷自动机） 以正则表达式主导的匹配。 时间复杂度最好是多项式级别的，最差是指数级别的。 支持捕获组和各种引用等。 采用贪婪匹配回溯的方式匹配。 如果是POSIX NFA，则会在可以确保已经找到可能的最长的匹配之前，将继续回溯。因而POSIX NFA的效率低于传统的NFA效率。 使用传统型NFA的引擎 GUN Emacs，Java，.NET，Ruby，Perl，PHP，Python，Sed，vi等。 使用POSIX NFA的引擎 使用DFA/NFA混合的引擎 GNU awk,GNU grep/egrep等。 注意DFA会在编译阶段对表达式进行分析，生成映射关系，因而编译阶段NFA效率高于DFA。 匹配过程如Hello terrence，正则表达式为 /te(brence|rrence|rrencm)/ NFA 匹配 先在字符串中查找t然后匹配其后是否为e ，如果是e则继续，查找其后是否为b，如果不是则匹配其后是否为 r (此时淘汰brence选择项)。然后继续看其后是否依次为r，e，n，c，接着测试是否为 e，是e则匹配成功，不是则测试是否为m。 DFA匹配 从 Hello 中 H 开始依次查找 t，定位到 t ，已知其后为 e ，则查看表达式是否有 e ，此处正好有 e 。然后字符串 e 后为 r ，DFA依次测试表达式，此时 brence 不符合要求淘汰。rrence 和 rrencm 符合要求，然后DFA依次检查字符串，检测到rence 中的 e 时只有rence 分支符合。 NFA的匹配效率Alternation Can Be ExpensiveAlternation可能会导致更多的回溯。 举例如下:具有Alternation的正则：u|v|w|x|y|z固定的正则：[uvwxyz] 具有Alternation的正则每次匹配失败都需要回朔，固定的正则将一次匹配所有的。如果失败，只匹配一次。即极限情况下，具有Alternation的正则需要回溯的次数是固定正则回溯次数的六倍。 尽可能的明确^或$标识尽量确定行首或行尾的特征，使用^或者$来标识开始或结束，特别是表达式中包含贪婪匹配的元素时。 举例:假如用non-capturing group (?:) 匹配 http://baidu.com正则表达式如下(http?|ftp)://([^/\\r\\n]+)(/[^\\r\\n])?如果我并不关心protocol，可以加入non-capturing group(?:) ，改为(?:http?|ftp)://([^/\\r\\n]+)(/[^\\r\\n])?这样匹配时，会忽略掉protocol，提升效率。 提取重复内容h(?:as|at) vs. (?:has|hat) 重复功能可以提取出来，当作一个函数，从而减少回朔的次数。这里前面的正则表达式效率高于后面的。 将最有可能的匹配放在最前面假如我想匹配各种后缀(com net edu等)结尾的url，正则表达式如下 (?:com|edu|org|net|…)实际上每个后缀的域名数量是不同的，假如 .net .org 的域名很多，为了提高效率我们可以将域名按照数量从高到低排序，以减少回溯次数。原正则表达式则变为 (?:net|org|com|edu|…)。 用lookAround剔除掉部分无效的匹配","raw":null,"content":null,"categories":[],"tags":[{"name":"regex，DFA，NFA","slug":"regex，DFA，NFA","permalink":"http://yoursite.com/tags/regex，DFA，NFA/"}]},{"title":"Java Memory Model","slug":"jmm","date":"2017-05-13T03:57:31.000Z","updated":"2017-05-14T04:27:49.000Z","comments":true,"path":"2017/05/13/jmm/","link":"","permalink":"http://yoursite.com/2017/05/13/jmm/","excerpt":"","text":"##Java Memory Model线程之间的通信机制有两种：共享内存和消息传递。 线程之间的公共状态，在共享内存的并发模型里，是通过写-读内存中的公共状态来隐式进行通信。在消息传递的并发模型里，是通过明确的发送消息来显式进行通信。 线程之间的状态同步，在共享内存并发模型里，必须显式地指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式的。 Java并发采用的是共享内存模型，线程之间的内存公共状态的读写通信是透明的，状态同步是显式的，保证同步操作时线程之间是互斥的。 JVM内存模型中,程序计数器，虚拟机栈，本地方法栈都是线程私有的，他们存储的信息不存在可见性问题，是线程安全的。堆和方法区是线程共享的,存在可见性问题。 线程之间的通信是由JMM决定的，它决定了一个线程对共享变量的写入何时对另一个线程可见。相当于每个线程都有一个主内存中的变量副本，用于自身的操作。 JMM规范中有两条规定： 线程对共享变量的所有操作都必须在自己的工作内存中进行，不能直接从主内存中读写。 不同线程之间无法直接访问其他线程工作内存中的变量，线程间变量值的传递需要通过主内存来完成。 happen-before原则一个线程中的每个操作，happens-before 于该线程中的任意后续操作。一个监视器解锁，happens-before 于随后对这个监视器锁的加锁。一个volatile域的写，happens-before 于任意后续对这个volatile域的读。如果A happens-before B，且B happens-before C，那么A happens-before C。 两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行。happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。 指令重排序happen-before规则是编译器重排序和处理器重排序的基础。程序执行时，编译器和处理器会根据执行效率对程序进行指令重排序。编译器重排序，编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。(编译器级别)指令级重排序，现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。(cpu级别)内存系统重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。(CPU级别) 编译器重排序由JMM的编译器重排序规则来禁止，处理器重排序可以通过内存屏障来禁止重排序。每个处理器processor的写缓冲区仅对自身可见。常见的处理器都允许store-load的重排序。 JMM的内存屏障分为以下四类:JMM内存屏障分为四类 LoadLoadBarries如：Load1–&gt;LoadLoad–&gt;Load2 确保load1数据装载一定在load2及所有后续装载指令1前装载。 StoreStoreBarries如：Store1–&gt;StroreStore–&gt;Store2 确保Store1数据对其他处理器可见一定在Store2及所有后续存储指令存储的前面。 LoadStoreBarries如：Load1–&gt;LoadStore–&gt;Store2 StoreLoadBarries如: Store1–&gt;StoreLoad–&gt;Load2 as-if-serial语义编译器和处理器不会改变存在数据依赖关系(仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不包括不同处理器之间和不同线程之间的)的两个操作的执行顺序。因此重排序并不会给单线程带来内存可见性问题。这个就是as-if-serial语义。 as-if-serial:无论如何重排序，程序执行的结果应该与代码顺序执行的结果一致(Java编译器,运行时和处理器都会保证java在单线程下遵循as-if-serial语义)。 原子性JMM对正确同步的多线程程序的内存一致性做了如下保证：如果程序是正确同步的，程序的执行将具有顺序一致性（sequentially consistent）即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同. 对64位(long,double)变量的读写可能不是原子操作，java内存模型允许JVM将没有被volatile修饰的64位数据类型的读写操作划分为两次32位的读写操作来完成。一般商用的JVM都对这部分做了原子性操作的保证，不用特意处理。导致问题：可能会出现读取到”半个变量”的情况解决办法：加volatile关键字。 加volatile关键字volatile能够保证volatile变量的可见性，不能保证volatile变量复合操作的原子性volatile如何实现内存可见性，深入来说通过加入内存屏障和禁止重排序优化来实现的。 对volatie变量执行写操作时，会在写操作后加入一条store屏障指令。 会把CPU写缓冲区的缓存强制刷新到主内存中。 防止处理器把volatile变量前面的操作重排序到valatile写操作之后。 对volatie变量执行读操作时，会在读操作前加入一条load屏障指令。 CPU缓冲区失效，从主内存读。 防止重排序。 volatile禁止重排序的规则 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。 volatile内存屏障的规则 在每个volatile写操作的前面插入一个StoreStore屏障。 在每个volatile写操作的后面插入一个StoreLoad屏障。 在每个volatile读操作的后面插入一个LoadLoad屏障。 在每个volatile读操作的后面插入一个LoadStore屏障。 锁和CAS锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。JVM中concurrent包中的锁主要依赖的是AbstractQueuedSynchronizer框架，即AQS实现的。AQS会维护一个volatile的Long型同步状态。 java的CAS同时具有 volatile 读和volatile写的内存语义，即编译器不能对CAS与CAS前面和后面的任意内存操作重排序。CAS会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键。volatile变量的读/写和CAS可以实现线程之间的通信，如下 A线程写volatile变量，随后B线程读这个volatile变量。 A线程写volatile变量，随后B线程用CAS更新这个volatile变量。 A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。 A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。 conocurrent包的通用实现模式 声明共享状态为volatile 使用CAS的原子条件更新来实现线程之间的同步 配合以volatile和CAS所具有的volatile读/写的内存语义,来实现线程之间的通信。 final对于final域，只要对象是正确构造的（被构造对象的引用在构造函数中没有“逸出”），那么不需要使用同步（指lock和volatile的使用），就可以保证任意线程都能看到这个final域在构造函数中被初始化之后的值。JSR133对写final域的重排序规则会要求译编器在final域的写之后，构造函数return之前，插入一个StoreStore障屏。读final域的重排序规则要求编译器在读final域的操作前面插入一个LoadLoad屏障。 JMM在不同的处理器中需要插入的内存屏障的数量和种类也不相同。 对于不计写读操作的处理器，JMM需要插入的内存屏障为StoreLoad Barries 对于不计写读操作和写写操作的处理器, JMM需要插入的内存屏障为StoreLoad Barries,StoreStore Barries. 对于不计写读，写写，读写和读读操作的处理器，JMM需要插入的内存屏障为StoreLoad Barries,StoreStore Barries,LoadStore Barries,LoadLoad Barries. JSR-133对JDK5之前的旧内存模型的修补主要有两方面： 增强volatile的内存语义。旧内存模型允许volatile变量与普通变量重排序。JSR-133严格限制volatile变量与普通变量的重排序，使volatile的写-读和锁的释放-获取具有相同的内存语义。 增强final的内存语义。在旧内存模型中，多次读取同一个final变量的值可能会不相同。JSR-133为final增加了两个重排序规则。保证了final初始化的安全性。即如果一个对象的引用在构造阶段不允许逸出（escape），那么一旦构造函数完成，并且线程发布了对另一个对象的引用，那么在不使用同步的条件下，这个对象的final域字段就能保证对所有其他线程是可见的、正确的并且是不变的。","raw":null,"content":null,"categories":[],"tags":[{"name":"JMM","slug":"JMM","permalink":"http://yoursite.com/tags/JMM/"}]},{"title":"javaio","slug":"javaio","date":"2017-04-11T15:03:54.000Z","updated":"2017-04-11T15:03:54.000Z","comments":true,"path":"2017/04/11/javaio/","link":"","permalink":"http://yoursite.com/2017/04/11/javaio/","excerpt":"","text":"","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Java Class文件","slug":"javaclass","date":"2017-04-10T15:50:29.000Z","updated":"2017-04-10T16:00:30.000Z","comments":true,"path":"2017/04/10/javaclass/","link":"","permalink":"http://yoursite.com/2017/04/10/javaclass/","excerpt":"","text":"Java Class文件Java Class文件是Java支持跨平台的基础，它是由不同位数的字节组成的，也称为字节码文件。其组织结构如下","raw":null,"content":null,"categories":[],"tags":[{"name":"JDK,Class文件","slug":"JDK-Class文件","permalink":"http://yoursite.com/tags/JDK-Class文件/"}]},{"title":"Java类编译，加载，执行","slug":"javacompile","date":"2017-03-20T15:16:36.000Z","updated":"2017-07-22T14:54:23.000Z","comments":true,"path":"2017/03/20/javacompile/","link":"","permalink":"http://yoursite.com/2017/03/20/javacompile/","excerpt":"","text":"Java类编译，加载和执行Java类的编译，加载和执行，常常被人们忽略。现在我们来看看这块具体的相关知识。 1.Java类编译Javac编译类的步骤如下: a.调用com.sun.tools.javac.parser.Scanner对java类做词法分析，将代码字符串转变为token序列。b.调用com.sun.tools.javac.parser.Parser对token序列做语法分析，将token序列生成抽象语法树。c.调用com.sun.tools.javac.comp.Enter将符号输入到符号表，通常包括确定类的超类型和接口，类构造器及符号等。d.如果当前类包含用户自定义的注解,则会进行注解处理，生成附加代码或进行特殊检查,并再次进入a-c的步骤来进行词法和语法分析并输入到符号表。e.基于抽象语法树进行语义分析，将语法树中的名字，表达式等元素与变量，方法，类型作关联，检查变量使用前是否已声明，推导泛型参数类型，检查类型匹配，检查变量赋值，检查语句可达性，去掉语法糖等。d.语义分析完成后，调用com.sun.tools.javac.jvm.gen来生成class文件。生成的大致步骤如下：将实例成员初始化器收集到构造器中，将静态成员初始化器收集到()中d.语义分析完成后，调用com.sun.tools.javac.jvm.gen来生成class文件。生成的大致步骤如下：将实例成员初始化器收集到构造器中，将静态成员初始化器收集到()中。后续遍历抽象语法树，进行少量的代码转换，生成字节码，最后从符号表生成class文件。e.class文件不仅包含了字节码，还包含了JVM用来执行class的附加信息。概括来说：包括class文件格式版本号及各部分的数量与大小信息。元数据-类、继承的超类、实现的接口声明，域与方法声明信息和常量池。方法信息-字节码，异常处理表，求值栈与局部变量区大小，求值栈的类型记录，调式用符号信息。 2.Java类加载Java JVM将类加载分为三个阶段:装载，链接和初始化。链接又细分为验证，准备，解析三个阶段。其中装载，验证，准备和初始化发生的顺序是确定的，但之间却没有严格的顺序完成的要求，通常都是各个阶段间交替混合进行的。而解析阶段没有这种顺序的要求，可能再初始化之后，也可能在其之前。 .class文件装载和链接过程完成后，即将二进制的字节码转换为Class对象，初始化过程不是加载类时必须触发的，但最迟必须在第一次主动使用对象前执行(给静态变量赋值，调用()等)。而一个类的声明周期除了上面三个阶段外，还包括使用，卸载两步。如下所示： a.装载load(查找并加载类的二机制数据)装载主要涉及的类为java.lang.ClassLoader，装载Class的二进制字节码并加载到JVM中，通过类的全限定名及类加载器完成类加载。具体的加载过程如下：(1)通过类的全限定名来获取该类的二进制字节流，来源可能是一个本地class文件，网络下载的class文件，动态生成的class文件，jar或者zip中的class文件，或是专有数据库中提取的class文件等。(2)将该字节流所代表的静态存储结构存储到方法区，转换为方法区的数据结构。(3)在堆内存中生成一个当前类的java.lang.Class对象，作为方法区数据结构的访问入口。JVM比较两个类是否相同，不仅比较类的全名，还比较加载此类的类加载器。只有两者都相同的时候，认为两个是相同的类。这也是代理模式的设计动机，即为了保证Java核心库的类型安全。所有Java应用都至少需要引用java.lang.Object类，通过代理模式，对于Java核心库的类的加载工作由引导类加载器来统一完成，保证了Java应用所使用的都是同一个版本的Java核心库的类，是互相兼容的。真正完成类的加载工作是通过调用defineClass来实现的,如果调用失败会报java.lang.NoClassDefFoundError；而类启动的加载过程是通过调用loadClass来实现的，如果失败会报java.lang.ClassNotFoundException。 b.链接(确保被加载的类的正确性)链接主要是对二进制class文件进行格式校验，初始化装载类中的静态变量及当前类中引用的接口和其他类。链接可以分为三个阶段验证，准备，解析。验证阶段，如果class文件格式验证有问题，会抛出java.lang.VerifyError的错误。校验过程如果需要加载其他的引用接口和类，也会进行加载，如果找不到，则会报java.lang.NoClassDefFoundError。验证分为四个方面的检查:(1)文件格式验证:验证字节流是否符合class文件格式的要求，如是否以OXCAFEBABE开头,版本号是否支持等。(2)原数据验证:对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范的要求，如这个类是否有父类。(3)字节码验证:通过数据流和控制流分析，确定程序语义是合法的。(4)符号引用验证:确保解析动作能正确执行。 准备阶段，为类的静态变量分配内存,并将其初始化为默认值,是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意：1、这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。2、这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。假设一个类变量的定义为：public static int value = 100；那么变量value在准备阶段过后的初始值为0，而不是100，因为这时候尚未开始执行任何Java方法，而把value赋值为100的putstatic指令是在程序编译后，存放于类构造器（）方法之中的，所以把value赋值为100的动作将在初始化阶段才会执行。· 这里还需要注意如下几点：· 对基本数据类型来说，对于类变量（static）和全局变量，如果不显式地对其赋值而直接使用，则系统会为其赋予默认的零值，而对于局部变量来说，在使用前必须显式地为其赋值，否则编译时不通过。· 对于同时被static和final修饰的常量，必须在声明的时候就为其显式地赋值，否则编译时不通过；而只被final修饰的常量则既可以在声明时显式地为其赋值，也可以在类初始化时显式地为其赋值，总之，在使用前必须为其显式地赋值，系统不会为其赋予默认零值。· 对于引用数据类型reference来说，如数组引用、对象引用等，如果没有对其进行显式地赋值而直接使用，系统都会为其赋予默认的零值，即null。· 如果在数组初始化时没有对数组中的各元素赋值，那么其中的元素将根据对应的数据类型而被赋予默认的零值。 3、如果类字段的字段同时被final和static修饰，那么在准备阶段变量value就会被初始化为所指定的值。假设上面的类变量value被定义为： public static final int value = 200；在准备阶段虚拟机就会将value赋值为200. 解析阶段，是虚拟机将常量池内的符号引用替换为直接引用的过程。对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行解析。如果这个阶段失败，会产生NoSuchMethodError，NoSuchFieldError等错误。JVM实现的解析策略可能互不同。一种是在链接的时候，就把所有依赖的引用都解析出来。而另外一种则是只有在这个引用真正要用到的时候,才进行解析。 c.初始化初始化过程主要操作的静态初始化代码，构造器代码以及静态属性的初始化。初始化执行前，必须完成链接的校验和准备阶段，解析没有特别要求。触发java接口和类初始化的情况有以下几种：1.创建实例2.子类初始化3.JVM启动过程中指定的初始化类4.反射调用了类中的方法5.调用类的静态方法6.访问某个类或者接口的静态变量，或者对该静态变量赋值 d.JVM结束生命周期1.执行了system.exit()方法2.程序正常执行结束3.程序执行过程中遇到了异常或错误而异常中止4.操作系统错误导致的JVM进程挂掉 3.Java类执行 a.解释执行解释执行主要是JVM基于字节码进行的。具体的JVM采用了invokestatic，invokevirtual，invokeinterface和invokespecial来执行不同的方法调用。invokestatic对应的是static方法的调用。invokevirtual对应的是对象实例方法的调用。invokeinterface对应的是接口方法的调用。invokespecial对应的是private方法和方法的调用。b.编译执行JDK提供将字节码编译为机器码的支持，编译在执行时执行频率较高的代码。JDK在编译上提供了两种模式:clent compiler(-client)和server compiler(-server)JDK主要是根据栈的结构来执行字节码的，具体如下图： SUN JDK对Java类执行的一些优化：1.操作数栈顶的数据直接缓存在寄存器中，对于大部分只需要一个值的操作，无需再将数据放入操作数栈，可直接在寄存器计算。2.栈帧共享，后面调用的方法将前一个方法的操作数栈作为当前方法的局部变量。减少数据copy的性能消耗。3.编译执行(JIT编译器)对执行频繁的代码采用编译执行，他包含两种模式:client compiler(-client)即c1和server compiler(-server)即c2。 c1的优化client compiler(c1)主要用于桌面交互的应用，在寄存器分配策略上，JDK6以后采用的为线性扫描寄存器分配算法。还有就是方法内联，去虚拟化，冗余削除等。-XX:+PrintInlining来查看方法内联的信息。去虚拟化是在装载class文件后，进行类层次的分析，如果类中的方法只提供一个实现类，那么对于调用了此方法的代码，也可进行方法内联，从而提升执行的性能。冗余削除是指在编译时，根据运行状况进行代码折叠或削除。 c2的优化c2在寄存器分配策略上，采用传统的图着色寄存器分配算法。C2的优化主要机遇逃逸分析。逃逸分析指的是JVM根据运行状况来判断当前方法中的变量是否被外部引用，如果外部不引用，则认为是逃逸的。基于逃逸分析，主要的优化点有：标量替换，栈上分配和同步削除等。 默认情况在，JDK根据机器配置来选择client或server模式，32位windows机器始终选择的是client模式，当机器配置超过2核且内存&gt;2G默认为server模式。可以通过启动参数-client或-server强制指定。 JDK未选择启动时即编译成机器码的原因1.静态编译后无法根据运行情况做优化。2.解释执行比编译执行更节省内存。3.启动时的解释执行速度比编译后再启动更快。 JDK用于权衡编译和解释代码的转换，主要基于两个维度的统计值。 1.调用计数器,即方法被调用的次数。CompileThreshold该值是指当方法被调用多少次后，就会被编译为机器码。在client模式下默认为1500次，在server模式下默认为10 000次，可通过在启动时添加-XX:CompileThreshold=10000来设置该值。 2.回边计数器,即循环体内代码被执行的次数。OnStackReplacePercentage该值为用于计算是否触发OSR编译的阈值，默认情况下client模式时为933，server模式下为140，该值可通过在启动时添加-XX: OnStackReplacePercentage=140来设置，在client模式时，计算规则为CompileThreshold (OnStackReplacePercentage/100)，在server模式时，计算规则为(CompileThreshold (OnStackReplacePercentage - InterpreterProfilePercentage))/100。InterpreterProfilePercentage默认值为33。","raw":null,"content":null,"categories":[],"tags":[{"name":"Java原理","slug":"Java原理","permalink":"http://yoursite.com/tags/Java原理/"}]},{"title":"JAVA IO -- File","slug":"file","date":"2017-02-10T03:54:15.000Z","updated":"2017-02-10T03:55:19.000Z","comments":true,"path":"2017/02/10/file/","link":"","permalink":"http://yoursite.com/2017/02/10/file/","excerpt":"","text":"","raw":null,"content":null,"categories":[],"tags":[{"name":"JAVA IO, JDK , File","slug":"JAVA-IO-JDK-File","permalink":"http://yoursite.com/tags/JAVA-IO-JDK-File/"}]},{"title":"zab 协议","slug":"zab","date":"2016-12-29T01:27:47.000Z","updated":"2017-02-03T10:03:33.000Z","comments":true,"path":"2016/12/29/zab/","link":"","permalink":"http://yoursite.com/2016/12/29/zab/","excerpt":"","text":"Zab 协议ZAB协议是专门为ZooKeeper设计的崩溃可恢复的原子消息广播算法。ZooKeeper的分布式一致性主要由ZAB协议来实现。它通过一个单一的主进程来接收并处理客户端的所有事务请求，并采用ZAB的原子广播协议，将服务器的状态变更以事务Proposal的形式广播到所有的副本进程上去。协议的核心是所有事务请求必须由一个全局唯一的服务器来协调处理，即leader，而余下的其他服务器则为follower。leader服务器负责将一个客户端事务请求转换为一个事务Proposal提议，并将该Proposal分发给集群中所有的Follower服务器。如果Leader接收到了超过半数的Follower服务器进行了正确的反馈，leader就会再次向Follower发送Commit消息，要求其将前一个Proposal提交。 ZAB协议包含两个重要部分:崩溃恢复和消息广播。 一个由3台机器组成的ZAB服务，通常由一个leader，2个follower服务器组成。某个时间加入一个Follower服务器挂了,整个ZAB集群是不会中断服务的，因为leader服务器仍然可以获得过半的机器包括自身的支持。","raw":null,"content":null,"categories":[],"tags":[{"name":"zab, ZooKeeper","slug":"zab-ZooKeeper","permalink":"http://yoursite.com/tags/zab-ZooKeeper/"}]},{"title":"zookeeper简介","slug":"zookeeper","date":"2016-12-25T07:34:57.000Z","updated":"2016-12-29T11:07:45.000Z","comments":true,"path":"2016/12/25/zookeeper/","link":"","permalink":"http://yoursite.com/2016/12/25/zookeeper/","excerpt":"","text":"zookeeper简介zookeeper为分布式应用提供了高效可靠的基础服务，它并没有直接实用paxos算法作为分布式一致性上的解决方法，而是采用了ZAB协议(ZooKeeper Atomic Broadcast)。它提供了如下特性：1.顺序一致性，即从同一个客户端发起的事务请求，最终将会严格地按照其发送顺序被应用到ZooKeeper中。2.原子性，所有事务请求最终处理的结果在整个集群是一致的，不存在一部分执行了该事务，一部分没有的情况。3.单一视图，无论客户端连接的是哪台zookeeper服务器，其看到的服务端数据模型都是一致的。4.可靠性，一旦服务端成功应用了一条事务，并完成对客户端的响应，那么该事务所引起的服务端状态的变更会一直保持下去，直到一个新的事务对其做了改变。5.实时性，zookeeper能够保证在一定的时间段内，客户端最终一定能从服务端读到最新状态的数据。 zookeeper的设计目标:1.简单数据模型: zookeeper的树型命名空间由一系列ZNode结点组成，有点类似于文件系统的层级结构。2.方便构建集群: 3-5台机器即可组成一个集群。每台机器都会在内存中维护当前的服务器状态，且每台服务器之间保持互相通信。3.支持顺序访问。4.高性能。全部数据存储在内存中，尤其适用于读操作的场景。 zookeeper集群它并非传统的master/slave式的集群模式，而是采用了leader，follower和observer三种角色。zookeeper中包含一台选举出来的leader，它提供客户端的读写服务。其他机器为Follower和observer，他们只提供读服务。且二者之间的区别在于，follower除了提供读服务外，还参与leader的选举，以及写操作的”过半写成功”策略。 session会话客户端于服务器建立第一次连接开始，客户端的会话生命周期也同事开始。通过这个长连接，客户端可以通过心跳机制来于服务端保持会话的有效性。如果客户端因为服务器压力过大，或网络故障等等造成的断开，只要在sessionTimeOut之前重新于集群建立连接，都认为会话仍有效。 数据节点ZNode即为数据模型中的数据单元,zookeeper的所有数据都存储在一个树型结构的内存模型中。比如/path/foo1就是一个znode，每个znode不仅存储数据，也存储一系列属性信息。ZNode有永久结点和临时结点的区分。临时结点与客户端会话相关。znode的版本，zookeeper会为每个znode维护一个stat，包含version znode的当前版本,cversion znode的子节点版本和aversion znode的ACL版本 watcher监听器zookeeper允许用户在指定节点注册时间监听器。zookeeper会在事件触发后发送给感兴趣的用户。 ACL权限控制1.CREATE 创建子节点的权限。2.READ 获取节点数据和子节点列表的权限。3.WRITE 更新节点数据的权限4.DELETE 删除子节点的权限5.ADMIN 设置节点ACL的权限","raw":null,"content":null,"categories":[],"tags":[{"name":"分布式一致性,zookeeper,ZAB","slug":"分布式一致性-zookeeper-ZAB","permalink":"http://yoursite.com/tags/分布式一致性-zookeeper-ZAB/"}]},{"title":"paxos在chubby的应用","slug":"paxosinchubby","date":"2016-12-12T11:49:32.000Z","updated":"2016-12-25T07:32:34.000Z","comments":true,"path":"2016/12/12/paxosinchubby/","link":"","permalink":"http://yoursite.com/2016/12/12/paxosinchubby/","excerpt":"","text":"paxos在chubby中的应用 paxos在chubby中主要作为日志层一致性的保证，为上层的分布式锁和数据库提供保障。 paxos算法的作用就在于保证chubby集群内各个副本节点的日志能够保持一致。chubby事务日志中的每个value对应的Paxos算法中的一个instance。在整个chubby运行过程中，会存在多个Paxos instance。chubby会为每个Paxos instance按序分配一个全局唯一的Instance编号，并顺序写入tvirsConfigMapper到事务日志中去。在多模式下，为了提升算法执行的性能，就必须选举出一个副本节点作为paxos算法的主节点，以避免多个Paxos Round并存的情况。具体地：prepare-&gt;promise-&gt;propose-&gt;accept 当前至多存在k个未达成一致的Instance，将这些未决的instance各自最后接受的提案值(若尚未接受任何值,则用null来代替。)作为promise消息返回。 判断N是否大于当前Acceptor的最大提案编号，如果大于该值，则标记所有未决instance和所有未来的instance的最大提案编号为n，这样未决的和所有未来的instance都不能接受提案编号小于n的提案。在master稳定的情况下，只需要使用一个相同的编号来执行每个instance的promise-&gt;accept模式，一旦在单个的instance中接收到了多数派的Accept反馈，即可将对应的提案值写入本地事务日志并广播commit消息告诉集群中的其他副本节点，以便于其他副本节点写入。如果某台宕机，可以主动向其他副本节点进行查询。 chubby的数据库层 数据快照+事务日志，定期的数据快照避免日志过大，造成的宕机恢复时间较长。如果磁盘损坏，只能从其他副本节点索取全量的状态数据了。另外如果磁盘未损坏，宕机瞬间丢失的日志数据也可以通过其他副本节点做恢复。","raw":null,"content":null,"categories":[],"tags":[{"name":"chubby paxos","slug":"chubby-paxos","permalink":"http://yoursite.com/tags/chubby-paxos/"}]},{"title":"chubby介绍","slug":"chubby","date":"2016-10-22T05:52:42.000Z","updated":"2017-03-15T15:47:44.000Z","comments":true,"path":"2016/10/22/chubby/","link":"","permalink":"http://yoursite.com/2016/10/22/chubby/","excerpt":"","text":"chubby chubby系统架构 大致如下图所示： 一个由chubby cell组成的chubby server集群,客户端的chubby lib通过Rpc协议与服务端进行通讯，chubby cell之间通过paxos算法选举server中的master。 目录与文件chubby的数据结构可以看作是一个由文件和目录组成的树。/chubby节点的公共前缀/chubby集群的名字/业务的相对路径, Chubby服务器内部可以解析并定位到数据节点。 chubby 包括acl元信息，及四个单调递增的64位编码。实例编码，文件内容编码，锁编码，ACL编码消息乱序或延迟造成锁失效。如一个客户端c1获取到了互斥锁L，并且在锁L的保护下发出的请求R，但请求R迟迟没有到达服务器，这时应用程序会认为该客户端进程已经失败，于是便会为另一个客户端C2分配了锁L，然后再重新发送请求R，并且成功的应用到了服务器上，此时，不幸的事情发生了，客户端C1的请求R在经过一波三折之后也到达了服务端， chubby中任意一个数据节点都可以充当一个读写锁来使用，一种是单个客户端以排他(写)模式持有这个锁，另一种则是任意数目的客户端以共享(读)模式持有这个锁。chubby舍弃了严格的强制锁，客户端可以在没有获取任何锁的情况下访问chubby的文件。 chubby中解决消息延迟和重排序引起的分布式锁问题，采用锁延迟和锁序列器两种策略。chubby 客户端以正常的方式主动释放一个锁，那么chubby服务端将会允许其他客户端能够立即获取到该锁。如果是因为客户端异常而被释放的话，那么chubby服务器会为该锁保留一定的时间，称之为锁延迟。锁序列器,该策略需要chubby的上层应用配合在代码中加入相应的修改逻辑。 chubby中的事件通知机制客户端向服务端注册事件通知，服务端根据事件通知来通知对应的客户端。 chubby客户端的缓存策略chubby客户端缓存一致性问题的处理，通过租期机制来保证缓存一致性。chubby缓存的生命周期和master租期机制紧密相关，master会维护每个客户端的数据缓存情况，并通过向客户端发送过期信息的方式来保证客户端数据的一致性。这样，chubby就能保证客户端要么能从缓存中访问到一致的数据，要么访问出错。每个客户端的缓存都有一个租期，一旦该租期到期，客户端就需要向服务端续订租期以继续维持缓存的有效性，当文件数据或元数据修改时，chubby会首先阻塞该修改操作，由master向所有缓存了该缓存的客户端发送缓存过期信号，以使其缓存过期。master在接收到所有客户端针对该缓存的应答后，再进行修改操作。 chubby服务端处理客户端的保持连接的请求，收到后会先阻塞等待该客户端的租期即将过期时，才会对它的租期进行续租，续租后向客户端返回保持连接请求的应答。chubby的租期会话时间默认为12s，但会根据具体负载进行调节。客户端收到保持连接的响应后，会立即向服务端发一个保持连接的请求，服务端再次阻塞。 chubby master选举后的基本流程1.master选举后，会确定master周期，master周期确定后，如果再收到客户端携带的其他master的编号的请求，则会拒绝。并告知客户端更新master的编号。master只要发生重新选取，即需要重新确定周期。2.选举产生的新的master会立即对寻址的客户端请求进行响应，但不会立即对客户端的会话请求进行处理。3.master会根据本地存储的会话和锁信息，来构建服务器内存状态。4.master处理客户端的keepalive请求。5.master向所有客户端发送一个故障切换的请求，等待所有的客户端接收到侯清空本地缓存，警告上层缓存失效。并应答回master。6.master开始处理会话级的请求。如果客户端调用了一个故障切换前创建的句柄，当前的master会重新创建合格内存对象。","raw":null,"content":null,"categories":[],"tags":[{"name":"分布式锁,GFS,Big Table","slug":"分布式锁-GFS-Big-Table","permalink":"http://yoursite.com/tags/分布式锁-GFS-Big-Table/"}]},{"title":"paxos 算法","slug":"paxos","date":"2016-10-16T17:15:01.000Z","updated":"2016-12-24T10:06:09.000Z","comments":true,"path":"2016/10/17/paxos/","link":"","permalink":"http://yoursite.com/2016/10/17/paxos/","excerpt":"","text":"分布式一致性的背景1.面临的问题通讯异常，网络分区，三态（成功，失败，超时），节点故障2.相关的概念(1) ACID原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）(2) CAP原理指的是 一致性(CONSISTENCY)可用性(AVAILABILITY)分区容忍性(PARTITION TOLERANCE)这三个要素最多只能同时实现两点，不可能三者兼顾。在进行分布式架构设计时，必须做出取舍。而对于分布式数据系统，分区容忍性是基本要求，否则就失去了价值。一般情况下分布式数据系统，就是在一致性和可用性之间取一个平衡。对于大多数WEB应用，其实并不需要强一致性，因此牺牲一致性而换取高可用性，是多数分布式产品的方向。(3) BASE理论BASE理论是最终一致性的理论支撑，它的全称是 Basically Available（基本可用），Soft-state（软状态/柔性事务)，Eventually Consistent（最终一致性）。在理论逻辑上它是相反于ACID模型的，它牺牲高一致性，获得可用性和分区容忍性。 一致性模型的类型：(1) Weak 弱一致性：当你写入一个新值后，读操作在数据副本上可能读出来，也可能读不出来。比如：网络游戏其它玩家的数据，VOIP系统等。(2) Eventually 最终一致性：当你写入一个新值后，有可能读不出来，但在某个时间窗口之后保证最终能读出来。比如：DNS，电子邮件、Amazon S3，Google搜索引擎等。(3) Strong 强一致性：新的数据一旦写入，在任意副本任意时刻都能读到新值。比如：文件系统，RDBMS，Azure Table等。 分布式算法1.PC二段提交第一阶段：协调者向所有参与者发送”是否可以提交”–&gt; 参与者开始做执行准备:资源上锁,预留资源，写入undo/redo日志(便于回滚),准备成功则回应”可以提交”，否则回应”拒绝”第二阶段：所有参与者回应“可以提交” –&gt; 协调者向所有的参与者发送“正式提交”命令 –&gt; 参与者完成正式提交,释放资源，回应”完成” –&gt; 协调者收集到所有”提交完成”，结束事务。任意一个参与者回应”拒绝提交” –&gt; 协调者向所有的参与者发送“回滚”命令 –&gt; 参与者释放所有资源，回应”回滚完成”–&gt; 协调者收集到所有”回滚完成”，取消整个事务。 优势:原理实现简单劣势:单点问题–&gt;协调者同步阻塞问题脑裂问题–&gt;协调者区域网络断开，导致双主。过于保守–&gt;所有参与者都要响应(如:参与者超时返回,参与者响应后协调者错误导致参与者所处的状态等)。 2.三阶段提交(1) 阶段1：事务询问协调者发送一个包含事务的can commit请求,询问是否可以提交操作—&gt;参与者向协调者反馈事务询问的响应 (2) 阶段2：precommit执行事务预先提交：协调者向所有参与者发送precommit请求 –&gt; 参与者收到precommit请求后，执行事务操作，写undo，redo信息。–&gt; 所有参与者成功执行事务操作,反馈ACK响应给协调者,并等待下一步指令:commit 或者 abort。 中断事务：任何一个参与者ACK了No或者等待超时后,仍有参与者未反馈响应,则中断事务。协调者向所有参与者发送中断请求 –&gt; 参与者中断事务(参与者无论是否收到协调者的abort请求或等待协调者过程中发生超时,参与者都会中断事务) (3) docommit执行提交协调者向所有参与者发送提交请求 –&gt; 参与者提交事务,释放事务执行期间所占用的资源,完成后向协调者发送ACK消息,反馈事务提交的结果 –&gt; 协调者接收到所有参与者的ack后完成事务。 中断事务协调者收到任一个参与者的No ACK,或者因为网络故障造成的响应超时, 协调者发送中断请求–&gt; 参与者事务回滚，释放执行期间的资源占用,反馈事务的提交结果 –&gt; 协调者收到所有反馈后,中断事务 优缺点：优点：对比2阶段提交，3阶段提交降低了参与者的阻塞范围, 在出现单点故障后继续达成一致。缺点：参与者收到precommit消息后，如果和协调者无法网络通讯，会提交事务，导致数据不一致。 拜占庭将军问题 (Byzantine Generals Problem) 拜占庭将军问题的大致描述如下:两支军队，各有一个将军，他们准备协同攻击同样的一座城市，唯一的通信方式就是派各自的信使来往于山谷。但存在会被抓获的危险。当且仅当两支军队同时进攻这座城市才会成功。这种情形下两支军队需要进行沟通，来确定一个进攻时间。这将导致一个问题：试图通过建立在一个不可靠的连接上的交流，来协同一项行动的隐患和设计上的巨大挑战。 Paxos算法 Paxos算法是基于消息传递,具有高度容错特性的一致性算法，是当前解决分布式一致性问题最有效的算法之一。该算法解决的问题就是如何在一个可能发生诸如机器宕机或网络异常等情况的分布式系统中，快速且正确的在集群内部对某个数据的值达成一致，并且保证不论发生以上任何异常都不会破坏整个系统的一致性。paxos的三个角色Proposer,Acceptor,learner.paxos算法大致分为两部分，提出提案和提案获取.1.提出提案: 分为prepare阶段和accept阶段prepare阶段Proposer选定出一个编号为N的提案,然后向acceptor的某个超过半数的子集成员发送编号为N的prepare请求。此时如果acceptor收到该编号为N的prepare请求,如果编号N大于它所有当前已经响应的请求编号，那么它就会将编号为N的提案作为响应反馈给Proposer，并且承诺不会再批准任何小于编号N的提案。accept阶段如果Proposer收到来自半数以上的Acceptor反馈的，编号N的Prepare请求响应，那么它就会发送一个针对N的值为Vn的Accept请求给Acceptor，这个Vn就是提案编号N的value值。如果acceptor收到这个针对N编号值为Vn的提案，且它尚未对大于编号N的Prepare请求作出响应，它就可以通过该提案。注意：为保证防止死循环,proposer选取一个主proposer。2.提案的获取：acceptor通过后通知learner集合，learner集合再负责通知其余的learner。","raw":null,"content":null,"categories":[],"tags":[{"name":"paxos,分布式","slug":"paxos-分布式","permalink":"http://yoursite.com/tags/paxos-分布式/"}]}]}